{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.6939 - accuracy: 0.4860\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4930\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5030\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5260\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5240\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5360\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5300\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5280\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5300\n",
      "16/16 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# 3. Chạy ví dụ sau và Giải thích (tài liệu [0.2] trg 13)\n",
    "#Import required packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "# Getting the data ready\n",
    "# Generate train dummy data for 1000 Students and dummy testfor 500\n",
    "#Columns :Age, Hours of Study &Avg Previous test scores\n",
    "np.random.seed(2018) #Setting seed for reproducibility\n",
    "train_data, test_data = np.random.random((1000, 3)),np.random.random((500, 3))\n",
    "#Generate dummy results for 1000 students : Whether Passed (1) or Failed (0)\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "#Defining the model structure with the required layers,\n",
    "# ofneurons, activation function and optimizers\n",
    "# tạo model bằng Sequential\n",
    "model = Sequential()\n",
    "# tạo 1 layer với 5 neurons, đầu vào = 3, activation = relu\n",
    "model.add(Dense(5, input_dim=3, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# loss:dự đoán sai bao nhiêu so với nhãn\n",
    "# metrics: đánh giá độ chính xác\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#Train the model and make predictions\n",
    "model.fit(train_data, labels, epochs=10, batch_size=32)\n",
    "#Make predictions from the trained model\n",
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "94/94 [==============================] - 1s 5ms/step - loss: 0.6933 - accuracy: 0.5045 - val_loss: 0.6932 - val_accuracy: 0.5015\n",
      "Epoch 2/10\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5123 - val_loss: 0.6934 - val_accuracy: 0.5020\n",
      "Epoch 3/10\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5020 - val_loss: 0.6933 - val_accuracy: 0.5020\n",
      "Epoch 4/10\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5117 - val_loss: 0.6924 - val_accuracy: 0.5145\n",
      "Epoch 5/10\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5038 - val_loss: 0.6928 - val_accuracy: 0.5135\n",
      "Epoch 6/10\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5155 - val_loss: 0.6923 - val_accuracy: 0.5125\n",
      "Epoch 7/10\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5162 - val_loss: 0.6927 - val_accuracy: 0.5120\n",
      "Epoch 8/10\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6920 - accuracy: 0.5170 - val_loss: 0.6930 - val_accuracy: 0.5065\n",
      "Epoch 9/10\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.5165 - val_loss: 0.6925 - val_accuracy: 0.5095\n",
      "Epoch 10/10\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6920 - accuracy: 0.5203 - val_loss: 0.6933 - val_accuracy: 0.5040\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4800\n",
      "[0.6940377950668335, 0.47999998927116394]\n",
      "['loss', 'accuracy']\n",
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.48874986],\n",
       "       [0.49101645],\n",
       "       [0.48759896],\n",
       "       [0.4892973 ],\n",
       "       [0.4858345 ],\n",
       "       [0.48773056],\n",
       "       [0.49061176],\n",
       "       [0.48792928],\n",
       "       [0.48766303],\n",
       "       [0.4892473 ]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "# Generate dummy training dataset\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_control_flow_v2()\n",
    "np.random.seed(2018)\n",
    "x_train = np.random.random((6000,10))\n",
    "y_train = np.random.randint(2, size=(6000, 1))\n",
    "# Generate dummy validation dataset\n",
    "x_val = np.random.random((2000,10))\n",
    "y_val = np.random.randint(2, size=(2000, 1))\n",
    "# Generate dummy test dataset\n",
    "x_test = np.random.random((2000,10))\n",
    "y_test = np.random.randint(2, size=(2000, 1))\n",
    "#Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=10,activation = \"relu\")) #Layer 1\n",
    "model.add(Dense(32,activation = \"relu\")) #Layer 2\n",
    "model.add(Dense(16,activation = \"relu\")) #Layer 3\n",
    "model.add(Dense(8,activation = \"relu\")) #Layer 4\n",
    "model.add(Dense(4,activation = \"relu\")) #Layer 5\n",
    "model.add(Dense(1,activation = \"sigmoid\")) #OutputLayer\n",
    "#cấu hình model\n",
    "# Compile xác định loss function, the optimizer và the metrics\n",
    "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "#train model\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=10,validation_data=(x_val,y_val))\n",
    "# epochs số lần lặp lại => epochs càng lớn, model được train nhiều hơn\n",
    "#evaluate(x=None, y=None, batch_size=None, verbose=1,sample_weight=None, steps=None)\n",
    "print(model.evaluate(x_test,y_test))\n",
    "print(model.metrics_names)\n",
    "#print 10 predictions\n",
    "pred = model.predict(x_test)\n",
    "pred[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anhdu\\AppData\\Local\\Temp\\ipykernel_19132\\1773766393.py:4: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"./train.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1017209, 9)\n",
      "   Store  DayOfWeek        Date  Sales  Customers  Open  Promo StateHoliday  \\\n",
      "0      1          5  2015-07-31   5263        555     1      1            0   \n",
      "1      2          5  2015-07-31   6064        625     1      1            0   \n",
      "2      3          5  2015-07-31   8314        821     1      1            0   \n",
      "3      4          5  2015-07-31  13995       1498     1      1            0   \n",
      "4      5          5  2015-07-31   4822        559     1      1            0   \n",
      "\n",
      "   SchoolHoliday  \n",
      "0              1  \n",
      "1              1  \n",
      "2              1  \n",
      "3              1  \n",
      "4              1  \n",
      "(1115, 10)\n",
      "   Store StoreType Assortment  CompetitionDistance  CompetitionOpenSinceMonth  \\\n",
      "0      1         c          a               1270.0                        9.0   \n",
      "1      2         a          a                570.0                       11.0   \n",
      "2      3         a          a              14130.0                       12.0   \n",
      "3      4         c          c                620.0                        9.0   \n",
      "4      5         a          a              29910.0                        4.0   \n",
      "\n",
      "   CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  \\\n",
      "0                    2008.0       0              NaN              NaN   \n",
      "1                    2007.0       1             13.0           2010.0   \n",
      "2                    2006.0       1             14.0           2011.0   \n",
      "3                    2009.0       0              NaN              NaN   \n",
      "4                    2015.0       0              NaN              NaN   \n",
      "\n",
      "     PromoInterval  \n",
      "0              NaN  \n",
      "1  Jan,Apr,Jul,Oct  \n",
      "2  Jan,Apr,Jul,Oct  \n",
      "3              NaN  \n",
      "4              NaN  \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./train.csv\")\n",
    "print(df.shape)\n",
    "print(df.head(5))\n",
    "\n",
    "store = pd.read_csv(\"./store.csv\")\n",
    "print(store.shape)\n",
    "print(store.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anhdu\\AppData\\Local\\Temp\\ipykernel_19132\\3776406293.py:5: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"./train.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct number of Days : 942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anhdu\\AppData\\Local\\Temp\\ipykernel_19132\\3776406293.py:21: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  df_new[\"Week\"] = df_new[\"Date\"].dt.week\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./train.csv\")\n",
    "# print(df.shape)\n",
    "# print(df.head(5))\n",
    "\n",
    "store = pd.read_csv(\"./store.csv\")\n",
    "# print(store.shape)\n",
    "# print(store.head(5))\n",
    "df_new = df.merge(store,on=[\"Store\"], how=\"inner\")\n",
    "# print(df_new.shape)\n",
    "print(\"Distinct number of Days :\", len(df_new[\"Date\"].unique()))\n",
    "df_new[\"DayOfWeek\"].value_counts()\n",
    "df_new['Date'] = pd.to_datetime(df_new['Date'], infer_datetime_format=True)\n",
    "df_new[\"Month\"] = df_new[\"Date\"].dt.month\n",
    "df_new[\"Quarter\"] = df_new[\"Date\"].dt.quarter\n",
    "df_new[\"Year\"] = df_new[\"Date\"].dt.year\n",
    "df_new[\"Day\"] = df_new[\"Date\"].dt.day\n",
    "df_new[\"Week\"] = df_new[\"Date\"].dt.week\n",
    "df_new[\"Season\"] = np.where(df_new[\"Month\"].isin([3,4,5]),\"Spring\",\n",
    " np.where(df_new[\"Month\"].isin([6,7,8]),\n",
    "\"Summer\",\n",
    " np.where(df_new[\"Month\"].isin\n",
    "([9,10,11]),\"Fall\",\n",
    " np.where(df_new[\"Month\"].isin\n",
    "([12,1,2]),\"Winter\",\"None\"))))\n",
    "df_new.isnull().sum()/df_new.shape[0] * 100\n",
    "#Replace nulls with the mode\n",
    "df_new[\"CompetitionDistance\"]=df_new[\"CompetitionDistance\"].fillna(df_new[\"CompetitionDistance\"].mode()[0])\n",
    "#Double check if we still see nulls for the column\n",
    "df_new[\"CompetitionDistance\"].isnull().sum()/df_new.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Data: (1017209, 44)\n",
      "Distinct Datatypes: [dtype('int64') dtype('O') dtype('float64')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "target = [\"Sales\"]\n",
    "numeric_columns = [\"Customers\",\"Open\",\"Promo\",\"Promo2\",\n",
    "\"StateHoliday\",\"SchoolHoliday\",\"CompetitionDistance\"]\n",
    "categorical_columns = [\"DayOfWeek\",\"Quarter\",\"Month\",\"Year\",\n",
    "\"StoreType\",\"Assortment\",\"Season\"]\n",
    "#Define a function that will intake the raw dataframe and the column name and return a one hot encoded DF\n",
    "def create_ohe(df, col):\n",
    " le = LabelEncoder()\n",
    " a=le.fit_transform(df_new[col]).reshape(-1,1)\n",
    " ohe = OneHotEncoder(sparse=False)\n",
    " column_names = [col+ \"_\"+ str(i) for i in le.classes_]\n",
    " return(pd.DataFrame(ohe.fit_transform(a),columns =column_names))\n",
    "#Since the above function converts the column, one at a time\n",
    "#We create a loop to create the final dataset with all features\n",
    "temp = df_new[numeric_columns]\n",
    "for column in categorical_columns:\n",
    " temp_df = create_ohe(df_new,column)\n",
    " temp = pd.concat([temp,temp_df],axis=1)\n",
    "print(\"Shape of Data:\",temp.shape)\n",
    "print(\"Distinct Datatypes:\",temp.dtypes.unique())\n",
    "temp[\"StateHoliday\"]= np.where(temp[\"StateHoliday\"]== '0',0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (732390, 44)\n",
      "Shape of x_val: (81377, 44)\n",
      "Shape of x_test: (203442, 44)\n",
      "Shape of y_train: (732390, 1)\n",
      "Shape of y_val: (81377, 1)\n",
      "Shape of y_test: (203442, 1)\n",
      "Average Sales : Sales    5773.099997\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(temp, df_new[target],test_size=0.2,random_state=2018)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,test_size=0.1,random_state=2018)\n",
    "print(\"Shape of x_train:\",x_train.shape)\n",
    "print(\"Shape of x_val:\",x_val.shape)\n",
    "print(\"Shape of x_test:\",x_test.shape)\n",
    "print(\"Shape of y_train:\",y_train.shape)\n",
    "print(\"Shape of y_val:\",y_val.shape)\n",
    "print(\"Shape of y_test:\",y_test.shape)\n",
    "mean_sales = y_train.mean()\n",
    "print(\"Average Sales :\",mean_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11444/11444 [==============================] - 32s 3ms/step - loss: 956.5339 - mean_absolute_error: 956.5339 - val_loss: 834.0677 - val_mean_absolute_error: 834.0677\n",
      "Epoch 2/10\n",
      "11444/11444 [==============================] - 26s 2ms/step - loss: 786.3468 - mean_absolute_error: 786.3468 - val_loss: 752.9906 - val_mean_absolute_error: 752.9906\n",
      "Epoch 3/10\n",
      "11444/11444 [==============================] - 20s 2ms/step - loss: 742.8049 - mean_absolute_error: 742.8049 - val_loss: 728.4300 - val_mean_absolute_error: 728.4300\n",
      "Epoch 4/10\n",
      "11444/11444 [==============================] - 18s 2ms/step - loss: 724.7351 - mean_absolute_error: 724.7351 - val_loss: 714.9333 - val_mean_absolute_error: 714.9333\n",
      "Epoch 5/10\n",
      "11444/11444 [==============================] - 20s 2ms/step - loss: 713.3405 - mean_absolute_error: 713.3405 - val_loss: 701.8889 - val_mean_absolute_error: 701.8889\n",
      "Epoch 6/10\n",
      "11444/11444 [==============================] - 21s 2ms/step - loss: 706.5668 - mean_absolute_error: 706.5668 - val_loss: 698.0588 - val_mean_absolute_error: 698.0588\n",
      "Epoch 7/10\n",
      "11444/11444 [==============================] - 24s 2ms/step - loss: 701.3314 - mean_absolute_error: 701.3314 - val_loss: 694.3074 - val_mean_absolute_error: 694.3074\n",
      "Epoch 8/10\n",
      "11444/11444 [==============================] - 20s 2ms/step - loss: 697.2288 - mean_absolute_error: 697.2288 - val_loss: 697.3387 - val_mean_absolute_error: 697.3387\n",
      "Epoch 9/10\n",
      "11444/11444 [==============================] - 22s 2ms/step - loss: 693.2523 - mean_absolute_error: 693.2523 - val_loss: 692.0214 - val_mean_absolute_error: 692.0214\n",
      "Epoch 10/10\n",
      "11444/11444 [==============================] - 22s 2ms/step - loss: 688.4497 - mean_absolute_error: 688.4497 - val_loss: 680.0787 - val_mean_absolute_error: 680.0787\n",
      "6358/6358 [==============================] - 13s 2ms/step - loss: 676.3958 - mean_absolute_error: 676.3958\n",
      "Metric  loss : 676.4\n",
      "Metric  mean_absolute_error : 676.4\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "model = Sequential()\n",
    "model.add(Dense(150,input_dim = 44,activation=\"relu\"))\n",
    "#The input_dim =44, since the width of the training data=44 (refer data engg section)\n",
    "model.add(Dense(1,activation = \"linear\"))\n",
    "model.compile(optimizer='adam',loss=\"mean_absolute_error\", metrics=[\"mean_absolute_error\"])\n",
    "#Train the model\n",
    "model.fit(x_train.values,y_train.values, validation_data= (x_val,y_val),epochs=10,batch_size=64)\n",
    "result = model.evaluate(x_test,y_test)\n",
    "for i in range(len(model.metrics_names)):\n",
    " print(\"Metric \",model.metrics_names[i],\":\",str(round(result[i],2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6358/6358 [==============================] - 9s 1ms/step - loss: 676.3958 - mean_absolute_error: 676.3958\n",
      "Metric  loss : 676.4\n",
      "Metric  mean_absolute_error : 676.4\n"
     ]
    }
   ],
   "source": [
    "# Testing the Model Performance\n",
    "#Use the model's evaluate method to predict and evaluate the\n",
    "# test datasets\n",
    "result = model.evaluate(x_test.values,y_test.values)\n",
    "#Print the results\n",
    "for i in range(len(model.metrics_names)):\n",
    " print(\"Metric \",model.metrics_names[i],\":\",str(round(result[i],2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11444/11444 [==============================] - 46s 4ms/step - loss: 1727195.5000 - mean_absolute_error: 852.1113 - val_loss: 1135949.3750 - val_mean_absolute_error: 727.6134\n",
      "Epoch 2/10\n",
      "11444/11444 [==============================] - 36s 3ms/step - loss: 1155075.5000 - mean_absolute_error: 722.0324 - val_loss: 1011107.7500 - val_mean_absolute_error: 679.1361\n",
      "Epoch 3/10\n",
      "11444/11444 [==============================] - 42s 4ms/step - loss: 1085981.8750 - mean_absolute_error: 698.5538 - val_loss: 998221.8125 - val_mean_absolute_error: 681.3409\n",
      "Epoch 4/10\n",
      "11444/11444 [==============================] - 43s 4ms/step - loss: 1060057.7500 - mean_absolute_error: 691.3783 - val_loss: 1056187.3750 - val_mean_absolute_error: 687.3166\n",
      "Epoch 5/10\n",
      "11444/11444 [==============================] - 42s 4ms/step - loss: 1030575.8125 - mean_absolute_error: 682.1866 - val_loss: 954420.3125 - val_mean_absolute_error: 664.1273\n",
      "Epoch 6/10\n",
      "11444/11444 [==============================] - 37s 3ms/step - loss: 1007872.4375 - mean_absolute_error: 675.5812 - val_loss: 967937.8750 - val_mean_absolute_error: 665.6487\n",
      "Epoch 7/10\n",
      "11444/11444 [==============================] - 37s 3ms/step - loss: 988329.0625 - mean_absolute_error: 669.5453 - val_loss: 944102.1875 - val_mean_absolute_error: 668.5845\n",
      "Epoch 8/10\n",
      "11444/11444 [==============================] - 36s 3ms/step - loss: 962423.5000 - mean_absolute_error: 661.6716 - val_loss: 950038.7500 - val_mean_absolute_error: 658.2788\n",
      "Epoch 9/10\n",
      "11444/11444 [==============================] - 43s 4ms/step - loss: 943420.8750 - mean_absolute_error: 655.3544 - val_loss: 904518.9375 - val_mean_absolute_error: 648.6935\n",
      "Epoch 10/10\n",
      "11444/11444 [==============================] - 44s 4ms/step - loss: 923699.6875 - mean_absolute_error: 649.0566 - val_loss: 881866.5625 - val_mean_absolute_error: 645.1208\n",
      "Metric  loss : 676.4\n",
      "Metric  mean_absolute_error : 676.4\n"
     ]
    }
   ],
   "source": [
    "# Improving the Model\n",
    "model = Sequential()\n",
    "model.add(Dense(150,input_dim = 44,activation=\"relu\"))\n",
    "model.add(Dense(150,activation=\"relu\"))\n",
    "model.add(Dense(150,activation=\"relu\"))\n",
    "model.add(Dense(1,activation = \"linear\"))\n",
    "model.compile(optimizer='adam',loss=\"mean_squared_error\",metrics=[\"mean_absolute_error\"])\n",
    "history = model.fit(x_train,y_train, validation_data=(x_val,\n",
    "y_val),epochs=10,batch_size=64)\n",
    "#result = model.evaluate(x_test,y_test)\n",
    "for i in range(len(model.metrics_names)):\n",
    " print(\"Metric \",model.metrics_names[i],\":\",str(round(result[i],2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "11444/11444 [==============================] - 32s 3ms/step - loss: 1715532.8750 - mean_absolute_error: 850.5883 - val_loss: 1298729.8750 - val_mean_absolute_error: 762.9643\n",
      "Epoch 2/15\n",
      "11444/11444 [==============================] - 29s 3ms/step - loss: 1176380.5000 - mean_absolute_error: 727.0096 - val_loss: 1035422.1250 - val_mean_absolute_error: 694.0512\n",
      "Epoch 3/15\n",
      "11444/11444 [==============================] - 27s 2ms/step - loss: 1100505.5000 - mean_absolute_error: 702.1042 - val_loss: 1012048.6875 - val_mean_absolute_error: 681.0119\n",
      "Epoch 4/15\n",
      "11444/11444 [==============================] - 26s 2ms/step - loss: 1058877.0000 - mean_absolute_error: 689.8404 - val_loss: 1007616.1250 - val_mean_absolute_error: 670.1035\n",
      "Epoch 5/15\n",
      "11444/11444 [==============================] - 26s 2ms/step - loss: 1035893.6875 - mean_absolute_error: 682.3333 - val_loss: 1011315.2500 - val_mean_absolute_error: 690.9600\n",
      "Epoch 6/15\n",
      "11444/11444 [==============================] - 27s 2ms/step - loss: 1010276.8125 - mean_absolute_error: 674.7682 - val_loss: 986107.0000 - val_mean_absolute_error: 663.7747\n",
      "Epoch 7/15\n",
      "11444/11444 [==============================] - 25s 2ms/step - loss: 989684.3125 - mean_absolute_error: 668.7182 - val_loss: 920713.5000 - val_mean_absolute_error: 650.8321\n",
      "Epoch 8/15\n",
      "11444/11444 [==============================] - 25s 2ms/step - loss: 974138.1875 - mean_absolute_error: 663.3995 - val_loss: 948284.9375 - val_mean_absolute_error: 670.7950\n",
      "Epoch 9/15\n",
      "11444/11444 [==============================] - 26s 2ms/step - loss: 956796.5000 - mean_absolute_error: 657.4449 - val_loss: 935814.0625 - val_mean_absolute_error: 662.4479\n",
      "Epoch 10/15\n",
      "11444/11444 [==============================] - 25s 2ms/step - loss: 948055.5000 - mean_absolute_error: 654.3614 - val_loss: 965436.1250 - val_mean_absolute_error: 656.7993\n",
      "Epoch 11/15\n",
      "11444/11444 [==============================] - 25s 2ms/step - loss: 928744.9375 - mean_absolute_error: 648.6245 - val_loss: 863142.5000 - val_mean_absolute_error: 634.3247\n",
      "Epoch 12/15\n",
      "11444/11444 [==============================] - 26s 2ms/step - loss: 917368.0000 - mean_absolute_error: 644.6728 - val_loss: 1044480.7500 - val_mean_absolute_error: 707.1052\n",
      "Epoch 13/15\n",
      "11444/11444 [==============================] - 34s 3ms/step - loss: 902662.4375 - mean_absolute_error: 639.8774 - val_loss: 837434.6875 - val_mean_absolute_error: 619.6711\n",
      "Epoch 14/15\n",
      "11444/11444 [==============================] - 34s 3ms/step - loss: 892414.0625 - mean_absolute_error: 635.9366 - val_loss: 840695.5625 - val_mean_absolute_error: 622.6671\n",
      "Epoch 15/15\n",
      "11444/11444 [==============================] - 34s 3ms/step - loss: 883744.6250 - mean_absolute_error: 632.4766 - val_loss: 860324.8125 - val_mean_absolute_error: 623.7596\n",
      "6358/6358 [==============================] - 15s 2ms/step - loss: 861250.3750 - mean_absolute_error: 620.6992\n",
      "Metric  loss : 861250.38\n",
      "Metric  mean_absolute_error : 620.7\n"
     ]
    }
   ],
   "source": [
    "# Tăng layer\n",
    "model = Sequential()\n",
    "model.add(Dense(150,input_dim = 44,activation=\"relu\"))\n",
    "model.add(Dense(150,activation=\"relu\"))\n",
    "model.add(Dense(150,activation=\"relu\"))\n",
    "model.add(Dense(150,activation=\"relu\"))\n",
    "model.add(Dense(150,activation=\"relu\"))\n",
    "model.add(Dense(1,activation = \"linear\"))\n",
    "model.compile(optimizer='adam',loss=\"mean_squared_error\",metrics=[\"mean_absolute_error\"])\n",
    "model.fit(x_train,y_train, validation_data=(x_val,y_val),\n",
    "epochs=15,batch_size=64)\n",
    "result = model.evaluate(x_test,y_test)\n",
    "for i in range(len(model.metrics_names)):\n",
    " print(\"Metric \",model.metrics_names[i],\":\",str(round(result[i],2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increasing the Number of Neurons\n",
    "model = Sequential()\n",
    "model.add(Dense(350,input_dim = 44,activation=\"relu\"))\n",
    "model.add(Dense(350,activation=\"relu\"))\n",
    "model.add(Dense(1,activation = \"linear\"))\n",
    "model.compile(optimizer='adam',loss=\"mean_squared_error\",metrics=[\"mean_absolute_error\"])\n",
    "model.fit(x_train,y_train, validation_data=(x_val,y_val),\n",
    "epochs=15,batch_size=64)\n",
    "result = model.evaluate(x_test,y_test)\n",
    "for i in range(len(model.metrics_names)):\n",
    " print(\"Metric \",model.metrics_names[i],\":\",str(round(result[i],2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import History\n",
    "history = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(350,input_dim = 44,activation=\"relu\"))\n",
    "model.add(Dense(350,activation=\"relu\"))\n",
    "model.add(Dense(350,activation=\"relu\"))\n",
    "model.add(Dense(350,activation=\"relu\"))\n",
    "model.add(Dense(350,activation=\"relu\"))\n",
    "model.add(Dense(1,activation = \"linear\"))\n",
    "model.compile(optimizer='adam',loss=\"mean_squared_error\",metrics=[\"mean_absolute_error\"])\n",
    "model.fit(x_train,y_train, validation_data=(x_val,y_val),\n",
    "epochs=15,batch_size=64,callbacks=[history])\n",
    "result = model.evaluate(x_test,y_test)\n",
    "for i in range(len(model.metrics_names)):\n",
    " print(\"Metric \",model.metrics_names[i],\":\",str(round(result[i],2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Loss Metric Across Epochs\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Model's Training & Validation loss across epochs\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the Model Manually\n",
    "#Manually predicting from the model, instead of using model's evaluate function\n",
    "y_test[\"Prediction\"] = model.predict(x_test)\n",
    "y_test.columns = [\"Actual Sales\",\"Predicted Sales\"]\n",
    "print(y_test.head(10))\n",
    "#Manually predicting from the model, instead of using model's evaluate function\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "print(\"MSE :\",mean_squared_error(y_test[\"Actual Sales\"].\n",
    "values,y_test[\"Predicted Sales\"].values))\n",
    "print(\"MAE :\",mean_absolute_error(y_test[\"Actual Sales\"].\n",
    "values,y_test[\"Predicted Sales\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31e98c37b9cc7e46512ebe084386b0e5d5e209bf48f38eb64eb1a4dbc86c8947"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
